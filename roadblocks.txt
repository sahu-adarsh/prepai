fix#1 Throttling error
AI processing error: An error occurred (throttlingException) when calling the InvokeAgent operation: Your request rate is too high. Reduce the frequency of requests. Check your Bedrock model invocation quotas to find the acceptable frequency.

fix#2 Initial connection/authentication to AWS Bedrock
Fix: Connection Pooling + Keep-Alive

perf#3 Reduce initial greeting delay from 5-10s to 1-2s
Optimize WebSocket connection and greeting flow to provide faster interview start:
- Accept WebSocket connection before initializing models
- Replace Bedrock Agent greeting with fast template-based response
- Move S3 operations to async background tasks

perf#4 optimize Bedrock agent with session attributes and response filtering
- Reduce agent prompt from 1,289 to 230 words by moving interview configs to session attributes. 
Improves response time by 10-15% (6-8s → 5.5-7.5s).

fix#5 WebSocket state synchronization proved complex—handling bidirectional audio while managing conversation state, interruptions, and dropped connections required implementing a finite state machine. 

fix#6 Claude's responses included Markdown and stage directions like "smiling" that sounded robotic when spoken, so we built a text cleaning pipeline that removes formatting and truncates to conversational responses. 

perf#7 Lambda cold starts caused 2-3 second delays; we solved this with lazy loading and keeping models warm in global scope. 

fix#8 Audio format mismatches between browser capture (48kHz) and Whisper (16kHz) required resampling and manual WAV header construction. 

fix#9 Textract struggled with non-standard resumes, necessitating a PyPDF2 fallback and industry-specific skill extraction. 

perf#10 We optimized costs by switching from Claude 3.5 Sonnet to Haiku (90% reduction) and limiting conversation history.